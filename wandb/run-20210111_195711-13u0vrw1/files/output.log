
  | Name       | Type       | Params
------------------------------------------
0 | activation | LeakyReLU  | 0     
1 | layer1     | Sequential | 640   
2 | layer2     | Sequential | 73.9 K
3 | layer3     | Sequential | 295 K 
4 | layer4     | Sequential | 1.2 M 
5 | fc1        | Linear     | 262 K 
6 | fc2        | Linear     | 5.1 K 
------------------------------------------
1.8 M     Trainable params
0         Non-trainable params
1.8 M     Total params
/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional_tensor.py:876: UserWarning: Argument fill/fillcolor is not supported for Tensor input. Fill value is zero
  warnings.warn("Argument fill/fillcolor is not supported for Tensor input. Fill value is zero")
/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Trying to log at a previous step. Use `commit=False` when logging metrics manually.
  warnings.warn(*args, **kwargs)
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 49 < 5000; dropping {'train_loss': -0.0016787811182439327, 'train_loss1': 0.0007287805201485753, 'train_loss2': 0.0038125740829855204, 'train_loss3': 0.0014050123281776905}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 99 < 10000; dropping {'train_loss': -0.0038629546761512756, 'train_loss1': 0.015619425103068352, 'train_loss2': 0.02638346701860428, 'train_loss3': 0.006901087239384651}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 149 < 15000; dropping {'train_loss': -0.06916084885597229, 'train_loss1': 0.013987264595925808, 'train_loss2': 0.11706682294607162, 'train_loss3': 0.033918704837560654}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 199 < 20000; dropping {'train_loss': -0.10643094778060913, 'train_loss1': 0.06530138850212097, 'train_loss2': 0.2470666766166687, 'train_loss3': 0.0753343403339386}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 249 < 25000; dropping {'train_loss': -0.16858772933483124, 'train_loss1': 0.040582239627838135, 'train_loss2': 0.3269473910331726, 'train_loss3': 0.11777742207050323}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 299 < 30000; dropping {'train_loss': -0.161479651927948, 'train_loss1': 0.06535828858613968, 'train_loss2': 0.3670414686203003, 'train_loss3': 0.1402035355567932}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 349 < 35000; dropping {'train_loss': -0.17749108374118805, 'train_loss1': 0.04510798305273056, 'train_loss2': 0.3943571448326111, 'train_loss3': 0.17175807058811188}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 399 < 40000; dropping {'train_loss': -0.27737024426460266, 'train_loss1': 0.06098701059818268, 'train_loss2': 0.42279937863349915, 'train_loss3': 0.08444211632013321}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 449 < 45000; dropping {'train_loss': -0.3193027377128601, 'train_loss1': 0.038358964025974274, 'train_loss2': 0.4357762038707733, 'train_loss3': 0.07811451703310013}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 499 < 50000; dropping {'train_loss': -0.2296939343214035, 'train_loss1': 0.04832576960325241, 'train_loss2': 0.44842615723609924, 'train_loss3': 0.17040644586086273}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 549 < 55000; dropping {'train_loss': -0.2965441644191742, 'train_loss1': 0.0713636726140976, 'train_loss2': 0.4928632378578186, 'train_loss3': 0.12495538592338562}.
Epoch 0, global step 549: val_loss reached -0.26337 (best -0.26337), saving model to "/content/gdrive/My Drive/PUSHMI/saved_models/distance_100_5e-05_0.0/model-v0.ckpt" as top 1
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 549 < 55000; dropping {'val_loss': -0.2633679211139679, 'val_acc': 0.3486, 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 599 < 60000; dropping {'train_loss': -0.21191783249378204, 'train_loss1': 0.05851287022233009, 'train_loss2': 0.4669232964515686, 'train_loss3': 0.19649259746074677}.
/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  warnings.warn(*args, **kwargs)
Epoch 1, step 618: val_loss was not in top 1

/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Checkpoint directory /content/gdrive/My Drive/PUSHMI/saved_models/distance_100_5e-05_0.0 exists and is not empty.
  warnings.warn(*args, **kwargs)
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type       | Params
------------------------------------------
0 | activation | LeakyReLU  | 0     
1 | layer1     | Sequential | 640   
2 | layer2     | Sequential | 73.9 K
3 | layer3     | Sequential | 295 K 
4 | layer4     | Sequential | 1.2 M 
5 | fc1        | Linear     | 262 K 
6 | fc2        | Linear     | 5.1 K 
------------------------------------------
1.8 M     Trainable params
0         Non-trainable params
1.8 M     Total params
/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional_tensor.py:876: UserWarning: Argument fill/fillcolor is not supported for Tensor input. Fill value is zero
  warnings.warn("Argument fill/fillcolor is not supported for Tensor input. Fill value is zero")
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 0 < 61900; dropping {'val_loss': tensor(0.0014, device='cuda:0'), 'val_acc': 0.18}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 100 < 61900; dropping {'train_loss': tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 200 < 61900; dropping {'train_loss': tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 300 < 61900; dropping {'train_loss': tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 400 < 61900; dropping {'train_loss': tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 500 < 61900; dropping {'train_loss': tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 600 < 61900; dropping {'train_loss': tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 700 < 61900; dropping {'train_loss': tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 800 < 61900; dropping {'train_loss': tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 900 < 61900; dropping {'train_loss': tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1000 < 61900; dropping {'train_loss': tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1100 < 61900; dropping {'train_loss': tensor(-0.0002, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1200 < 61900; dropping {'train_loss': tensor(5.7649e-06, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1300 < 61900; dropping {'train_loss': tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1400 < 61900; dropping {'train_loss': tensor(-0.0002, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1500 < 61900; dropping {'train_loss': tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1600 < 61900; dropping {'train_loss': tensor(-0.0004, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1700 < 61900; dropping {'train_loss': tensor(-0.0004, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1800 < 61900; dropping {'train_loss': tensor(-0.0007, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1900 < 61900; dropping {'train_loss': tensor(-0.0002, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2000 < 61900; dropping {'train_loss': tensor(-0.0004, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2100 < 61900; dropping {'train_loss': tensor(-0.0006, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2200 < 61900; dropping {'train_loss': tensor(-0.0012, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2300 < 61900; dropping {'train_loss': tensor(-0.0004, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2400 < 61900; dropping {'train_loss': tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2500 < 61900; dropping {'train_loss': tensor(-0.0007, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2600 < 61900; dropping {'train_loss': tensor(-0.0012, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2700 < 61900; dropping {'train_loss': tensor(-0.0013, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2800 < 61900; dropping {'train_loss': tensor(-0.0019, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2900 < 61900; dropping {'train_loss': tensor(-0.0012, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3000 < 61900; dropping {'train_loss': tensor(-0.0022, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3100 < 61900; dropping {'train_loss': tensor(-0.0020, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3200 < 61900; dropping {'train_loss': tensor(-0.0033, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3300 < 61900; dropping {'train_loss': tensor(-0.0006, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3400 < 61900; dropping {'train_loss': tensor(-0.0020, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3500 < 61900; dropping {'train_loss': tensor(-0.0006, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3600 < 61900; dropping {'train_loss': tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3700 < 61900; dropping {'train_loss': tensor(-0.0022, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3800 < 61900; dropping {'train_loss': tensor(-0.0004, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3900 < 61900; dropping {'train_loss': tensor(-0.0024, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4000 < 61900; dropping {'train_loss': tensor(-0.0023, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4100 < 61900; dropping {'train_loss': tensor(-0.0028, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4200 < 61900; dropping {'train_loss': tensor(-0.0016, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4300 < 61900; dropping {'train_loss': tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4400 < 61900; dropping {'train_loss': tensor(-0.0006, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4500 < 61900; dropping {'train_loss': tensor(-0.0025, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4600 < 61900; dropping {'train_loss': tensor(-0.0011, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4700 < 61900; dropping {'train_loss': tensor(-0.0013, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4800 < 61900; dropping {'train_loss': tensor(-0.0028, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4900 < 61900; dropping {'train_loss': tensor(-0.0003, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5000 < 61900; dropping {'train_loss': tensor(-0.0020, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5100 < 61949; dropping {'train_loss': tensor(-0.0019, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5200 < 61949; dropping {'train_loss': tensor(-0.0026, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5300 < 61949; dropping {'train_loss': tensor(-0.0040, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5400 < 61949; dropping {'train_loss': tensor(-0.0038, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5500 < 61949; dropping {'train_loss': tensor(-0.0052, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5600 < 61949; dropping {'train_loss': tensor(-0.0042, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5700 < 61949; dropping {'train_loss': tensor(-0.0022, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5800 < 61949; dropping {'train_loss': tensor(-0.0052, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5900 < 61949; dropping {'train_loss': tensor(-0.0031, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6000 < 61949; dropping {'train_loss': tensor(-0.0028, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6100 < 61949; dropping {'train_loss': tensor(-0.0047, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6200 < 61949; dropping {'train_loss': tensor(-0.0039, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6300 < 61949; dropping {'train_loss': tensor(-0.0054, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6400 < 61949; dropping {'train_loss': tensor(-0.0025, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6500 < 61949; dropping {'train_loss': tensor(-0.0024, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6600 < 61949; dropping {'train_loss': tensor(-0.0047, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6700 < 61949; dropping {'train_loss': tensor(-0.0038, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6800 < 61949; dropping {'train_loss': tensor(-0.0060, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6900 < 61949; dropping {'train_loss': tensor(-0.0034, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7000 < 61949; dropping {'train_loss': tensor(-0.0083, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7100 < 61949; dropping {'train_loss': tensor(-0.0055, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7200 < 61949; dropping {'train_loss': tensor(-0.0080, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7300 < 61949; dropping {'train_loss': tensor(-0.0052, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7400 < 61949; dropping {'train_loss': tensor(-0.0074, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7500 < 61949; dropping {'train_loss': tensor(-0.0043, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7600 < 61949; dropping {'train_loss': tensor(-0.0077, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7700 < 61949; dropping {'train_loss': tensor(-0.0077, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7800 < 61949; dropping {'train_loss': tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7900 < 61949; dropping {'train_loss': tensor(-0.0078, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8000 < 61949; dropping {'train_loss': tensor(-0.0083, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8100 < 61949; dropping {'train_loss': tensor(-0.0086, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8200 < 61949; dropping {'train_loss': tensor(-0.0099, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8300 < 61949; dropping {'train_loss': tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8400 < 61949; dropping {'train_loss': tensor(-0.0090, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8500 < 61949; dropping {'train_loss': tensor(-0.0119, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8600 < 61949; dropping {'train_loss': tensor(-0.0064, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8700 < 61949; dropping {'train_loss': tensor(-0.0168, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8800 < 61949; dropping {'train_loss': tensor(-0.0080, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8900 < 61949; dropping {'train_loss': tensor(-0.0100, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9000 < 61949; dropping {'train_loss': tensor(-0.0092, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9100 < 61949; dropping {'train_loss': tensor(-0.0155, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9200 < 61949; dropping {'train_loss': tensor(-0.0121, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9300 < 61949; dropping {'train_loss': tensor(-0.0071, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9400 < 61949; dropping {'train_loss': tensor(-0.0141, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9500 < 61949; dropping {'train_loss': tensor(-0.0170, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9600 < 61949; dropping {'train_loss': tensor(-0.0157, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9700 < 61949; dropping {'train_loss': tensor(-0.0166, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9800 < 61949; dropping {'train_loss': tensor(-0.0113, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9900 < 61949; dropping {'train_loss': tensor(-0.0096, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10000 < 61949; dropping {'train_loss': tensor(-0.0083, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10100 < 61999; dropping {'train_loss': tensor(-0.0138, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10200 < 61999; dropping {'train_loss': tensor(-0.0212, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10300 < 61999; dropping {'train_loss': tensor(-0.0054, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10400 < 61999; dropping {'train_loss': tensor(-0.0152, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10500 < 61999; dropping {'train_loss': tensor(-0.0144, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10600 < 61999; dropping {'train_loss': tensor(-0.0224, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10700 < 61999; dropping {'train_loss': tensor(-0.0073, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10800 < 61999; dropping {'train_loss': tensor(-0.0243, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10900 < 61999; dropping {'train_loss': tensor(-0.0139, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11000 < 61999; dropping {'train_loss': tensor(-0.0143, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11100 < 61999; dropping {'train_loss': tensor(-0.0242, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11200 < 61999; dropping {'train_loss': tensor(-0.0263, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11300 < 61999; dropping {'train_loss': tensor(-0.0187, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11400 < 61999; dropping {'train_loss': tensor(-0.0309, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11500 < 61999; dropping {'train_loss': tensor(-0.0294, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11600 < 61999; dropping {'train_loss': tensor(-0.0217, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11700 < 61999; dropping {'train_loss': tensor(-0.0249, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11800 < 61999; dropping {'train_loss': tensor(-0.0207, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11900 < 61999; dropping {'train_loss': tensor(-0.0150, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12000 < 61999; dropping {'train_loss': tensor(-0.0332, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12100 < 61999; dropping {'train_loss': tensor(-0.0351, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12200 < 61999; dropping {'train_loss': tensor(-0.0338, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12300 < 61999; dropping {'train_loss': tensor(-0.0337, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12400 < 61999; dropping {'train_loss': tensor(-0.0394, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12500 < 61999; dropping {'train_loss': tensor(-0.0301, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12600 < 61999; dropping {'train_loss': tensor(-0.0340, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12700 < 61999; dropping {'train_loss': tensor(-0.0414, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12800 < 61999; dropping {'train_loss': tensor(-0.0423, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12900 < 61999; dropping {'train_loss': tensor(-0.0204, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 13000 < 61999; dropping {'train_loss': tensor(-0.0545, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 13100 < 61999; dropping {'train_loss': tensor(-0.0495, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 13200 < 61999; dropping {'train_loss': tensor(-0.0362, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 13300 < 61999; dropping {'train_loss': tensor(-0.0538, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 13400 < 61999; dropping {'train_loss': tensor(-0.0337, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 13500 < 61999; dropping {'train_loss': tensor(-0.0377, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 13600 < 61999; dropping {'train_loss': tensor(-0.0419, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 13700 < 61999; dropping {'train_loss': tensor(-0.0347, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 13800 < 61999; dropping {'train_loss': tensor(-0.0454, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 13900 < 61999; dropping {'train_loss': tensor(-0.0413, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 14000 < 61999; dropping {'train_loss': tensor(-0.0423, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 14100 < 61999; dropping {'train_loss': tensor(-0.0401, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 14200 < 61999; dropping {'train_loss': tensor(-0.0567, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 14300 < 61999; dropping {'train_loss': tensor(-0.0711, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 14400 < 61999; dropping {'train_loss': tensor(-0.0634, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 14500 < 61999; dropping {'train_loss': tensor(-0.0486, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 14600 < 61999; dropping {'train_loss': tensor(-0.0838, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 14700 < 61999; dropping {'train_loss': tensor(-0.0755, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 14800 < 61999; dropping {'train_loss': tensor(-0.0572, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 14900 < 61999; dropping {'train_loss': tensor(-0.0441, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 15000 < 61999; dropping {'train_loss': tensor(-0.0685, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 15100 < 62049; dropping {'train_loss': tensor(-0.0564, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 15200 < 62049; dropping {'train_loss': tensor(-0.0386, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 15300 < 62049; dropping {'train_loss': tensor(-0.0254, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 15400 < 62049; dropping {'train_loss': tensor(-0.0646, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 15500 < 62049; dropping {'train_loss': tensor(-0.0781, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 15600 < 62049; dropping {'train_loss': tensor(-0.1135, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 15700 < 62049; dropping {'train_loss': tensor(-0.0721, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 15800 < 62049; dropping {'train_loss': tensor(-0.1074, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 15900 < 62049; dropping {'train_loss': tensor(-0.0801, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 16000 < 62049; dropping {'train_loss': tensor(-0.0970, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 16100 < 62049; dropping {'train_loss': tensor(-0.0742, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 16200 < 62049; dropping {'train_loss': tensor(-0.0526, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 16300 < 62049; dropping {'train_loss': tensor(-0.0839, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 16400 < 62049; dropping {'train_loss': tensor(-0.0967, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 16500 < 62049; dropping {'train_loss': tensor(-0.0979, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 16600 < 62049; dropping {'train_loss': tensor(-0.0765, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 16700 < 62049; dropping {'train_loss': tensor(-0.0883, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 16800 < 62049; dropping {'train_loss': tensor(-0.1217, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 16900 < 62049; dropping {'train_loss': tensor(-0.1189, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 17000 < 62049; dropping {'train_loss': tensor(-0.1159, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 17100 < 62049; dropping {'train_loss': tensor(-0.0670, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 17200 < 62049; dropping {'train_loss': tensor(-0.0750, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 17300 < 62049; dropping {'train_loss': tensor(-0.0682, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 17400 < 62049; dropping {'train_loss': tensor(-0.1355, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 17500 < 62049; dropping {'train_loss': tensor(-0.0956, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 17600 < 62049; dropping {'train_loss': tensor(-0.1180, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 17700 < 62049; dropping {'train_loss': tensor(-0.1336, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 17800 < 62049; dropping {'train_loss': tensor(-0.1132, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 17900 < 62049; dropping {'train_loss': tensor(-0.1040, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 18000 < 62049; dropping {'train_loss': tensor(-0.0921, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 18100 < 62049; dropping {'train_loss': tensor(-0.0920, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 18200 < 62049; dropping {'train_loss': tensor(-0.1611, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 18300 < 62049; dropping {'train_loss': tensor(-0.0844, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 18400 < 62049; dropping {'train_loss': tensor(-0.0651, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 18500 < 62049; dropping {'train_loss': tensor(-0.1218, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 18600 < 62049; dropping {'train_loss': tensor(-0.0698, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 18700 < 62049; dropping {'train_loss': tensor(-0.1753, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 18800 < 62049; dropping {'train_loss': tensor(-0.1153, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 18900 < 62049; dropping {'train_loss': tensor(-0.1471, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 19000 < 62049; dropping {'train_loss': tensor(-0.1223, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 19100 < 62049; dropping {'train_loss': tensor(-0.1590, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 19200 < 62049; dropping {'train_loss': tensor(-0.1069, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 19300 < 62049; dropping {'train_loss': tensor(-0.1115, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 19400 < 62049; dropping {'train_loss': tensor(-0.1417, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 19500 < 62049; dropping {'train_loss': tensor(-0.0625, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 19600 < 62049; dropping {'train_loss': tensor(-0.1582, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 19700 < 62049; dropping {'train_loss': tensor(-0.1598, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 19800 < 62049; dropping {'train_loss': tensor(-0.1494, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 19900 < 62049; dropping {'train_loss': tensor(-0.1623, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 20000 < 62049; dropping {'train_loss': tensor(-0.1309, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 20100 < 62099; dropping {'train_loss': tensor(-0.0825, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 20200 < 62099; dropping {'train_loss': tensor(-0.1619, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 20300 < 62099; dropping {'train_loss': tensor(-0.1207, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 20400 < 62099; dropping {'train_loss': tensor(-0.1298, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 20500 < 62099; dropping {'train_loss': tensor(-0.0885, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 20600 < 62099; dropping {'train_loss': tensor(-0.1841, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 20700 < 62099; dropping {'train_loss': tensor(-0.1159, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 20800 < 62099; dropping {'train_loss': tensor(-0.1681, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 20900 < 62099; dropping {'train_loss': tensor(-0.1482, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 21000 < 62099; dropping {'train_loss': tensor(-0.1334, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 21100 < 62099; dropping {'train_loss': tensor(-0.1250, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 21200 < 62099; dropping {'train_loss': tensor(-0.1087, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 21300 < 62099; dropping {'train_loss': tensor(-0.0934, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 21400 < 62099; dropping {'train_loss': tensor(-0.1455, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 21500 < 62099; dropping {'train_loss': tensor(-0.1025, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 21600 < 62099; dropping {'train_loss': tensor(-0.1507, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 21700 < 62099; dropping {'train_loss': tensor(-0.2359, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 21800 < 62099; dropping {'train_loss': tensor(-0.1198, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 21900 < 62099; dropping {'train_loss': tensor(-0.1393, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 22000 < 62099; dropping {'train_loss': tensor(-0.1991, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 22100 < 62099; dropping {'train_loss': tensor(-0.1411, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 22200 < 62099; dropping {'train_loss': tensor(-0.1444, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 22300 < 62099; dropping {'train_loss': tensor(-0.1659, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 22400 < 62099; dropping {'train_loss': tensor(-0.1730, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 22500 < 62099; dropping {'train_loss': tensor(-0.1899, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 22600 < 62099; dropping {'train_loss': tensor(-0.1786, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 22700 < 62099; dropping {'train_loss': tensor(-0.2066, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 22800 < 62099; dropping {'train_loss': tensor(-0.1338, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 22900 < 62099; dropping {'train_loss': tensor(-0.1490, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 23000 < 62099; dropping {'train_loss': tensor(-0.1794, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 23100 < 62099; dropping {'train_loss': tensor(-0.1649, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 23200 < 62099; dropping {'train_loss': tensor(-0.1969, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 23300 < 62099; dropping {'train_loss': tensor(-0.1127, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 23400 < 62099; dropping {'train_loss': tensor(-0.1504, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 23500 < 62099; dropping {'train_loss': tensor(-0.1598, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 23600 < 62099; dropping {'train_loss': tensor(-0.2050, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 23700 < 62099; dropping {'train_loss': tensor(-0.1592, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 23800 < 62099; dropping {'train_loss': tensor(-0.1185, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  warnings.warn(*args, **kwargs)
