
  | Name       | Type       | Params
------------------------------------------
0 | activation | LeakyReLU  | 0     
1 | layer1     | Sequential | 640   
2 | layer2     | Sequential | 73.9 K
3 | layer3     | Sequential | 295 K 
4 | layer4     | Sequential | 1.2 M 
5 | fc1        | Linear     | 262 K 
6 | fc2        | Linear     | 5.1 K 
------------------------------------------
1.8 M     Trainable params
0         Non-trainable params
1.8 M     Total params
/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional_tensor.py:876: UserWarning: Argument fill/fillcolor is not supported for Tensor input. Fill value is zero
  warnings.warn("Argument fill/fillcolor is not supported for Tensor input. Fill value is zero")
/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Trying to log at a previous step. Use `commit=False` when logging metrics manually.
  warnings.warn(*args, **kwargs)
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 49 < 5000; dropping {'train_loss': -0.002720350632444024, 'train_loss1': 0.0012736000353470445, 'train_loss2': 0.006392785347998142, 'train_loss3': 0.0023988347966223955}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 99 < 10000; dropping {'train_loss': -0.015035555697977543, 'train_loss1': 0.005096787121146917, 'train_loss2': 0.03205182030797005, 'train_loss3': 0.0119194770231843}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 149 < 15000; dropping {'train_loss': -0.03623230755329132, 'train_loss1': 0.033331017941236496, 'train_loss2': 0.12576806545257568, 'train_loss3': 0.05620473623275757}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 199 < 20000; dropping {'train_loss': -0.16222436726093292, 'train_loss1': 0.03204389661550522, 'train_loss2': 0.26022109389305115, 'train_loss3': 0.06595282256603241}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 249 < 25000; dropping {'train_loss': -0.0502246618270874, 'train_loss1': 0.07580587267875671, 'train_loss2': 0.34979769587516785, 'train_loss3': 0.22376716136932373}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 299 < 30000; dropping {'train_loss': -0.16341085731983185, 'train_loss1': 0.08848626911640167, 'train_loss2': 0.44020235538482666, 'train_loss3': 0.18830524384975433}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 349 < 35000; dropping {'train_loss': -0.11901669204235077, 'train_loss1': 0.1045088991522789, 'train_loss2': 0.4009886085987091, 'train_loss3': 0.17746300995349884}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 399 < 40000; dropping {'train_loss': -0.2576085925102234, 'train_loss1': 0.045953959226608276, 'train_loss2': 0.4063960909843445, 'train_loss3': 0.10283355414867401}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 449 < 45000; dropping {'train_loss': -0.17142631113529205, 'train_loss1': 0.0513557493686676, 'train_loss2': 0.44913631677627563, 'train_loss3': 0.22635425627231598}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 499 < 50000; dropping {'train_loss': -0.3305218815803528, 'train_loss1': 0.07217300683259964, 'train_loss2': 0.4675069749355316, 'train_loss3': 0.06481209397315979}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 549 < 55000; dropping {'train_loss': -0.3579578995704651, 'train_loss1': 0.044892724603414536, 'train_loss2': 0.4832744896411896, 'train_loss3': 0.08042386174201965}.
Epoch 0, global step 549: val_loss reached -0.28878 (best -0.28878), saving model to "/content/gdrive/My Drive/PUSHMI/saved_models/distance_100_5e-05_0.0/model.ckpt" as top 1
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 549 < 55000; dropping {'val_loss': -0.28877589106559753, 'val_acc': 0.28, 'epoch': 0}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 599 < 60000; dropping {'train_loss': -0.31773439049720764, 'train_loss1': 0.10899912565946579, 'train_loss2': 0.4839763641357422, 'train_loss3': 0.057242851704359055}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 649 < 65000; dropping {'train_loss': -0.29064491391181946, 'train_loss1': 0.04890235513448715, 'train_loss2': 0.4710870385169983, 'train_loss3': 0.13153976202011108}.
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 699 < 70000; dropping {'train_loss': -0.23760060966014862, 'train_loss1': 0.07909887284040451, 'train_loss2': 0.48450812697410583, 'train_loss3': 0.1678086370229721}.
/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  warnings.warn(*args, **kwargs)
Epoch 1, step 720: val_loss was not in top 1

/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Checkpoint directory /content/gdrive/My Drive/PUSHMI/saved_models/distance_100_5e-05_0.0 exists and is not empty.
  warnings.warn(*args, **kwargs)
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type       | Params
------------------------------------------
0 | activation | LeakyReLU  | 0     
1 | layer1     | Sequential | 640   
2 | layer2     | Sequential | 73.9 K
3 | layer3     | Sequential | 295 K 
4 | layer4     | Sequential | 1.2 M 
5 | fc1        | Linear     | 262 K 
6 | fc2        | Linear     | 5.1 K 
------------------------------------------
1.8 M     Trainable params
0         Non-trainable params
1.8 M     Total params
/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional_tensor.py:876: UserWarning: Argument fill/fillcolor is not supported for Tensor input. Fill value is zero
  warnings.warn("Argument fill/fillcolor is not supported for Tensor input. Fill value is zero")
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 0 < 72100; dropping {'val_loss': tensor(0.0019, device='cuda:0'), 'val_acc': 0.12}.
100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 100 < 72100; dropping {'train_loss': tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 200 < 72100; dropping {'train_loss': tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 300 < 72100; dropping {'train_loss': tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 400 < 72100; dropping {'train_loss': tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
500
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 500 < 72100; dropping {'train_loss': tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
600
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 600 < 72100; dropping {'train_loss': tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
700
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 700 < 72100; dropping {'train_loss': tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
800
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 800 < 72100; dropping {'train_loss': tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
900
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 900 < 72100; dropping {'train_loss': tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
1000
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1000 < 72100; dropping {'train_loss': tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
1100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1100 < 72100; dropping {'train_loss': tensor(-7.2897e-05, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
1200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1200 < 72100; dropping {'train_loss': tensor(-7.1687e-05, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
1300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1300 < 72100; dropping {'train_loss': tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
1400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1400 < 72100; dropping {'train_loss': tensor(-0.0003, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
1500
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1500 < 72100; dropping {'train_loss': tensor(-2.8068e-06, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
1600
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1600 < 72100; dropping {'train_loss': tensor(-0.0003, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
1700
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1700 < 72100; dropping {'train_loss': tensor(-0.0002, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
1800
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1800 < 72100; dropping {'train_loss': tensor(-0.0005, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
1900
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 1900 < 72100; dropping {'train_loss': tensor(7.3521e-05, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
2000
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2000 < 72100; dropping {'train_loss': tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
2100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2100 < 72100; dropping {'train_loss': tensor(-0.0013, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
2200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2200 < 72100; dropping {'train_loss': tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
2300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2300 < 72100; dropping {'train_loss': tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
2400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2400 < 72100; dropping {'train_loss': tensor(-0.0011, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
2500
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2500 < 72100; dropping {'train_loss': tensor(-0.0004, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
2600
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2600 < 72100; dropping {'train_loss': tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
2700
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2700 < 72100; dropping {'train_loss': tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
2800
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2800 < 72100; dropping {'train_loss': tensor(-0.0016, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
2900
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 2900 < 72100; dropping {'train_loss': tensor(-0.0012, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
3000
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3000 < 72100; dropping {'train_loss': tensor(-0.0015, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
3100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3100 < 72100; dropping {'train_loss': tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
3200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3200 < 72100; dropping {'train_loss': tensor(-0.0022, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
3300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3300 < 72100; dropping {'train_loss': tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
3400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3400 < 72100; dropping {'train_loss': tensor(-0.0011, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
3500
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3500 < 72100; dropping {'train_loss': tensor(-0.0016, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
3600
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3600 < 72100; dropping {'train_loss': tensor(-0.0015, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
3700
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3700 < 72100; dropping {'train_loss': tensor(-0.0030, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
3800
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3800 < 72100; dropping {'train_loss': tensor(-0.0015, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
3900
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 3900 < 72100; dropping {'train_loss': tensor(-0.0020, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
4000
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4000 < 72100; dropping {'train_loss': tensor(-0.0030, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
4100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4100 < 72100; dropping {'train_loss': tensor(-0.0025, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
4200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4200 < 72100; dropping {'train_loss': tensor(-0.0033, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
4300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4300 < 72100; dropping {'train_loss': tensor(-0.0032, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
4400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4400 < 72100; dropping {'train_loss': tensor(-0.0042, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
4500
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4500 < 72100; dropping {'train_loss': tensor(-0.0026, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
4600
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4600 < 72100; dropping {'train_loss': tensor(-0.0047, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
4700
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4700 < 72100; dropping {'train_loss': tensor(-0.0028, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
4800
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4800 < 72100; dropping {'train_loss': tensor(-0.0031, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
4900
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 4900 < 72100; dropping {'train_loss': tensor(-0.0038, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
5000
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5000 < 72100; dropping {'train_loss': tensor(-0.0039, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
5100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5100 < 72149; dropping {'train_loss': tensor(-0.0065, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
5200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5200 < 72149; dropping {'train_loss': tensor(-0.0029, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
5300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5300 < 72149; dropping {'train_loss': tensor(-0.0016, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
5400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5400 < 72149; dropping {'train_loss': tensor(-0.0008, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
5500
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5500 < 72149; dropping {'train_loss': tensor(-0.0078, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
5600
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5600 < 72149; dropping {'train_loss': tensor(-0.0067, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
5700
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5700 < 72149; dropping {'train_loss': tensor(-0.0037, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
5800
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5800 < 72149; dropping {'train_loss': tensor(-0.0050, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
5900
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 5900 < 72149; dropping {'train_loss': tensor(-0.0060, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
6000
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6000 < 72149; dropping {'train_loss': tensor(-0.0049, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
6100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6100 < 72149; dropping {'train_loss': tensor(-0.0050, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
6200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6200 < 72149; dropping {'train_loss': tensor(-0.0052, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
6300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6300 < 72149; dropping {'train_loss': tensor(-0.0038, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
6400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6400 < 72149; dropping {'train_loss': tensor(-0.0039, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
6500
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6500 < 72149; dropping {'train_loss': tensor(-0.0066, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
6600
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6600 < 72149; dropping {'train_loss': tensor(-0.0058, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
6700
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6700 < 72149; dropping {'train_loss': tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
6800
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6800 < 72149; dropping {'train_loss': tensor(-0.0079, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
6900
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 6900 < 72149; dropping {'train_loss': tensor(-0.0097, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
7000
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7000 < 72149; dropping {'train_loss': tensor(-0.0084, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
7100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7100 < 72149; dropping {'train_loss': tensor(-0.0084, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
7200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7200 < 72149; dropping {'train_loss': tensor(-0.0094, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
7300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7300 < 72149; dropping {'train_loss': tensor(-0.0038, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
7400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7400 < 72149; dropping {'train_loss': tensor(-0.0046, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
7500
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7500 < 72149; dropping {'train_loss': tensor(-0.0039, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
7600
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7600 < 72149; dropping {'train_loss': tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
7700
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7700 < 72149; dropping {'train_loss': tensor(-0.0056, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
7800
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7800 < 72149; dropping {'train_loss': tensor(-0.0109, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
7900
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 7900 < 72149; dropping {'train_loss': tensor(-0.0107, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
8000
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8000 < 72149; dropping {'train_loss': tensor(-0.0097, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
8100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8100 < 72149; dropping {'train_loss': tensor(-0.0098, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
8200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8200 < 72149; dropping {'train_loss': tensor(-0.0105, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
8300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8300 < 72149; dropping {'train_loss': tensor(-0.0096, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
8400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8400 < 72149; dropping {'train_loss': tensor(-0.0145, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
8500
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8500 < 72149; dropping {'train_loss': tensor(-0.0087, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
8600
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8600 < 72149; dropping {'train_loss': tensor(-0.0115, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
8700
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8700 < 72149; dropping {'train_loss': tensor(-0.0084, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
8800
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8800 < 72149; dropping {'train_loss': tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
8900
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 8900 < 72149; dropping {'train_loss': tensor(-0.0075, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
9000
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9000 < 72149; dropping {'train_loss': tensor(-0.0120, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
9100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9100 < 72149; dropping {'train_loss': tensor(-0.0092, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
9200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9200 < 72149; dropping {'train_loss': tensor(-0.0087, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
9300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9300 < 72149; dropping {'train_loss': tensor(-0.0224, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
9400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9400 < 72149; dropping {'train_loss': tensor(-0.0147, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
9500
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9500 < 72149; dropping {'train_loss': tensor(-0.0150, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
9600
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9600 < 72149; dropping {'train_loss': tensor(-0.0187, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
9700
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9700 < 72149; dropping {'train_loss': tensor(-0.0164, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
9800
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9800 < 72149; dropping {'train_loss': tensor(-0.0105, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
9900
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 9900 < 72149; dropping {'train_loss': tensor(-0.0054, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
10000
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10000 < 72149; dropping {'train_loss': tensor(-0.0143, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
10100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10100 < 72199; dropping {'train_loss': tensor(-0.0303, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
10200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10200 < 72199; dropping {'train_loss': tensor(-0.0264, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
10300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10300 < 72199; dropping {'train_loss': tensor(-0.0202, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
10400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10400 < 72199; dropping {'train_loss': tensor(-0.0096, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
10500
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10500 < 72199; dropping {'train_loss': tensor(-0.0112, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
10600
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10600 < 72199; dropping {'train_loss': tensor(-0.0192, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
10700
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10700 < 72199; dropping {'train_loss': tensor(-0.0281, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
10800
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10800 < 72199; dropping {'train_loss': tensor(-0.0258, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
10900
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 10900 < 72199; dropping {'train_loss': tensor(-0.0300, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
11000
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11000 < 72199; dropping {'train_loss': tensor(-0.0305, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
11100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11100 < 72199; dropping {'train_loss': tensor(-0.0313, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
11200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11200 < 72199; dropping {'train_loss': tensor(-0.0313, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
11300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11300 < 72199; dropping {'train_loss': tensor(-0.0343, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
11400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11400 < 72199; dropping {'train_loss': tensor(-0.0123, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
11500
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11500 < 72199; dropping {'train_loss': tensor(-0.0371, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
11600
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11600 < 72199; dropping {'train_loss': tensor(-0.0236, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
11700
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11700 < 72199; dropping {'train_loss': tensor(-0.0393, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
11800
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11800 < 72199; dropping {'train_loss': tensor(-0.0329, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
11900
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 11900 < 72199; dropping {'train_loss': tensor(-0.0375, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
12000
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12000 < 72199; dropping {'train_loss': tensor(-0.0276, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
12100
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12100 < 72199; dropping {'train_loss': tensor(-0.0562, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
12200
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12200 < 72199; dropping {'train_loss': tensor(-0.0493, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
12300
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12300 < 72199; dropping {'train_loss': tensor(-0.0127, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
12400
[34m[1mwandb[0m: [33mWARNING[0m Step must only increase in log calls.  Step 12400 < 72199; dropping {'train_loss': tensor(-0.0288, device='cuda:0', grad_fn=<AddBackward0>), 'epoch': 0}.
/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  warnings.warn(*args, **kwargs)
